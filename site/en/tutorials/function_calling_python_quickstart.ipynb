{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2024 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeadDkMiISin"
      },
      "source": [
        "# Gemini API: Basic function calling with Python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEXQ3OwKIa-O"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://ai.google.dev/tutorials/function_calling_python_quickstart\"><img src=\"https://ai.google.dev/static/site-assets/images/docs/notebook-site-button.png\" height=\"32\" width=\"32\" />View on ai.google.dev</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/generative-ai-docs/blob/main/site/en/tutorials/function_calling_python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/google/generative-ai-docs/blob/main/site/en/tutorials/function_calling_python_quickstart.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFPBKLapSCkM"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFNV1e3ASJha"
      },
      "source": [
        "### Install the Python SDK\n",
        "\n",
        "The Python SDK for the Gemini API, is contained in the [`google-generativeai`](https://pypi.org/project/google-generativeai/) package. Install the dependency using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9OEoeosRTv-5"
      },
      "outputs": [],
      "source": [
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCFF5VSTbcAR"
      },
      "source": [
        "### Import packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRC2HngneEeQ"
      },
      "source": [
        "Import the necessary packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TS9l5igubpHO"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('â€¢', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHYFrFPjSGNq"
      },
      "source": [
        "### Set up your API key\n",
        "\n",
        "Before you can use the Gemini API, you must first obtain an API key. If you don't already have one, create a key with one click in Google AI Studio.\n",
        "\n",
        "<a class=\"button button-primary\" href=\"https://makersuite.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">Get an API key</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHhsUxDTdw0W"
      },
      "source": [
        "In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `API_KEY`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmSlTHXxb5pV"
      },
      "source": [
        "Once you have the API key, pass it to the SDK. You can do this in two ways:\n",
        "\n",
        "* Put the key in the `GOOGLE_API_KEY` environment variable (the SDK will automatically pick it up from there).\n",
        "* Pass the key to `genai.configure(api_key=...)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ab9ASynfcIZn"
      },
      "outputs": [],
      "source": [
        "# Or use `os.getenv('API_KEY')` to fetch an environment variable.\n",
        "API_KEY=userdata.get('API_KEY')\n",
        "\n",
        "genai.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFz04WEgOwWp"
      },
      "source": [
        "## Function calls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js4Y4mO20txL"
      },
      "source": [
        "The <a href=\"https://ai.google.dev/api/python/google/ai/generativelanguage\"><code>google.ai.generativelanguage</code></a> client library provides access to the low level types required for function calling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S53E0EE8TBUF"
      },
      "outputs": [],
      "source": [
        "import google.ai.generativelanguage as glm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFD4U7ym04F5"
      },
      "source": [
        "A `glm.Tool` contains a list of `glm.FunctionDeclarations`. These just describe the function, they don't implement it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "mNfJ8Hjj1BMd"
      },
      "outputs": [],
      "source": [
        "datetime = glm.Tool(\n",
        "    function_declarations=[\n",
        "      glm.FunctionDeclaration(\n",
        "        name='now',\n",
        "        description=\"Returns the current UTC date and time.\"\n",
        "      )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a11LZTKT1CRp"
      },
      "source": [
        "Pass a list of tools to the `genai.GenerativeModel` constructor to give the model access:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "aGEcm_lSOv_T"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel(\n",
        "    'gemini-pro',\n",
        "    tools=[datetime])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FANMyp-V1can"
      },
      "source": [
        "For this basic tools support use chat-mode since tools require multiple rounds of back and forth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "LRx-I8i41cxT"
      },
      "outputs": [],
      "source": [
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    'How many days until Christmas',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7GgtVSJ17kW"
      },
      "source": [
        "When the model needs to call a tool to answer a question it returns a `glm.Part` containing a `function_call` instead of a <a href=\"https://www.tensorflow.org/text/api_docs/python/text\"><code>text</code></a> attribute:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "zQmmIhneQV_J"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[index: 0\n",
              "content {\n",
              "  parts {\n",
              "    function_call {\n",
              "      name: \"now\"\n",
              "      args {\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "]"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woioLEWo4b5N"
      },
      "source": [
        "Reply with a `glm.Part` containing a `glm.FunctionResponse` to allow the model to finish the answer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "TbmidjuxSaH6"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\n",
        "  glm.Content(\n",
        "    parts=[glm.Part(\n",
        "        function_response = glm.FunctionResponse(\n",
        "          name='now',\n",
        "          response={'datetime': 'Sun Dec 5 03:33:56 PM UTC 2023'}\n",
        "        )\n",
        "    )]\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DmxLrJZ4sYl"
      },
      "source": [
        "The model may respond with either a <a href=\"https://www.tensorflow.org/text/api_docs/python/text\"><code>text</code></a> response or another `glm.FunctionCall`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "1EWmHodLVCLK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' Okay, Christmas this year, 2023, is on Monday, December 25th. That makes it 20 days from now.'"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyWYFj0b43X2"
      },
      "source": [
        "That `datetime` tool only contained a single function, which takes no arguments. Next try something more complex.\n",
        "\n",
        "LLMs are, generally, not 100% accurate at arithmetic:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "YCBm3EFDH0Kr"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "549899573314\n"
          ]
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat()\n",
        "\n",
        "a = 2312371\n",
        "b = 234234\n",
        "\n",
        "response = chat.send_message(\n",
        "    f\"What's {a} X {b} ?\",\n",
        "\n",
        ")\n",
        "print(response.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "u2cTnhrzIEQe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "541635908814"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a*b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmoe63Cd5-AF"
      },
      "source": [
        "Sometimes it's off by ~1%, sometimes it's off by 10X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "dt0NhB5NJAOz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: -1.53%\n"
          ]
        }
      ],
      "source": [
        "error_percent = (a*b - int(response.text.replace(',', '')))/(a*b) * 100\n",
        "\n",
        "print(f\"Error: {error_percent:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY6RmFQ76FVu"
      },
      "source": [
        "So, describe a calculator as a `glm.Tool`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "qCwHM4WbC4wb"
      },
      "outputs": [],
      "source": [
        "calculator = glm.Tool(\n",
        "    function_declarations=[\n",
        "      glm.FunctionDeclaration(\n",
        "        name='add',\n",
        "        description=\"Returns the sum of two numbers.\",\n",
        "        parameters=glm.Schema(\n",
        "            type=glm.Type.OBJECT,\n",
        "            properties={\n",
        "                'a': glm.Schema(type=glm.Type.NUMBER),\n",
        "                'b': glm.Schema(type=glm.Type.NUMBER)\n",
        "            },\n",
        "            required=['a','b']\n",
        "        )\n",
        "      ),\n",
        "      glm.FunctionDeclaration(\n",
        "        name='multiply',\n",
        "        description=\"Returns the product of two numbers.\",\n",
        "        parameters=glm.Schema(\n",
        "            type=glm.Type.OBJECT,\n",
        "            properties={\n",
        "                'a':glm.Schema(type=glm.Type.NUMBER),\n",
        "                'b':glm.Schema(type=glm.Type.NUMBER)\n",
        "            },\n",
        "            required=['a','b']\n",
        "        )\n",
        "      )\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS6ruiTp6VBf"
      },
      "source": [
        "Give the model the calculator and ask again:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "xwhWG22cIIDU"
      },
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro', tools=[calculator])\n",
        "chat = model.start_chat()\n",
        "\n",
        "response = chat.send_message(\n",
        "    f\"What's {a} X {b} ?\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "517ca06297bb"
      },
      "source": [
        "Now instead of guessing at the answer the model returns a `glm.FunctionCall` invoking the calculator's `multiply` function: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "xhey4QA0DTJf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[index: 0\n",
              "content {\n",
              "  parts {\n",
              "    function_call {\n",
              "      name: \"multiply\"\n",
              "      args {\n",
              "        fields {\n",
              "          key: \"b\"\n",
              "          value {\n",
              "            number_value: 234234\n",
              "          }\n",
              "        }\n",
              "        fields {\n",
              "          key: \"a\"\n",
              "          value {\n",
              "            number_value: 2312371\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "    }\n",
              "  }\n",
              "  role: \"model\"\n",
              "}\n",
              "finish_reason: STOP\n",
              "]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.candidates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07eecbaedd5e"
      },
      "source": [
        "Execute the function yourself:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "88758eebfd5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "541635908814.0"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fc = response.candidates[0].content.parts[0].function_call\n",
        "assert fc.name == 'multiply'\n",
        "\n",
        "result = fc.args['a'] * fc.args['b']\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6ef0e9651cf"
      },
      "source": [
        "Send the result to the model, to continue the conversation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "f3c67066411e"
      },
      "outputs": [],
      "source": [
        "response = chat.send_message(\n",
        "    glm.Content(\n",
        "    parts=[glm.Part(\n",
        "        function_response = glm.FunctionResponse(\n",
        "          name='multiply',\n",
        "          response={'result': result}\n",
        "        )\n",
        "    )]\n",
        "  )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "9f7a9662d816"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "' 541636000000'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7c032834f41"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Basic function calling is supported in the SDK. Remember that it is easier to manage using chat-mode, because of the natural back and forth structure. You're in charge of actually calling the functions and sending results back to the model so it can produce a text-response. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "function_calling_python_quickstart.ipynb",
      "toc_visible": true
    },
    "google": {
      "image_path": "/site-assets/images/share.png",
      "keywords": [
        "examples",
        "googleai",
        "samplecode",
        "python",
        "embed",
        "function"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
